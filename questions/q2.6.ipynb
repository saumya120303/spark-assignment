{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting server on port 8006...\n"
     ]
    }
   ],
   "source": [
    "from http.server import BaseHTTPRequestHandler, HTTPServer\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum\n",
    "import os\n",
    "from glob import glob\n",
    "import json\n",
    "\n",
    "class HTTPRequestHandler(BaseHTTPRequestHandler):\n",
    "    def do_GET(self):\n",
    "        if self.path == '/most_efficient_country':\n",
    "            # Create a SparkSession\n",
    "            spark = SparkSession.builder \\\n",
    "                .appName(\"Most Efficient Country\") \\\n",
    "                .getOrCreate()\n",
    "\n",
    "            # Define the directory containing the CSV files\n",
    "            directory = \"/Users/saumya/Documents/spark-project/\"\n",
    "\n",
    "            # Find all CSV files in the directory\n",
    "            file_paths = glob(os.path.join(directory, \"*.csv\"))\n",
    "\n",
    "            # Read each CSV file into a DataFrame\n",
    "            dfs = [spark.read.csv(file_path, header=True, inferSchema=True) for file_path in file_paths]\n",
    "\n",
    "            # Union all DataFrames\n",
    "            merged_df = dfs[0]\n",
    "            for df in dfs[1:]:\n",
    "                merged_df = merged_df.union(df)\n",
    "\n",
    "            # Calculate total COVID-19 cases and total recoveries for each country\n",
    "            country_stats = merged_df.groupBy(\"country\") \\\n",
    "                .agg(sum(\"cases\").alias(\"total_cases\"), sum(\"recovered\").alias(\"total_recovered\"))\n",
    "\n",
    "            # Calculate efficiency ratio (total recoveries / total cases) for each country\n",
    "            country_stats = country_stats.withColumn(\"efficiency_ratio\", col(\"total_recovered\") / col(\"total_cases\"))\n",
    "\n",
    "            # Find the country with the highest efficiency ratio\n",
    "            most_efficient_country = country_stats.orderBy(col(\"efficiency_ratio\").desc()).select(\"country\").first()[0]\n",
    "\n",
    "            # Stop the SparkSession\n",
    "            spark.stop()\n",
    "\n",
    "            # Send response\n",
    "            self.send_response(200)\n",
    "            self.send_header('Content-type', 'application/json')\n",
    "            self.end_headers()\n",
    "            response = {'most_efficient_country': most_efficient_country}\n",
    "            self.wfile.write(json.dumps(response).encode())\n",
    "\n",
    "        else:\n",
    "            # Send 404 response for other paths\n",
    "            self.send_response(404)\n",
    "            self.end_headers()\n",
    "            self.wfile.write(b'404 Not Found')\n",
    "\n",
    "def run_server(port=8006):\n",
    "    server_address = ('', port)\n",
    "    httpd = HTTPServer(server_address, HTTPRequestHandler)\n",
    "    print(f'Starting server on port {port}...')\n",
    "    httpd.serve_forever()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_server()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
