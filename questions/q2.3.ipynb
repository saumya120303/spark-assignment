{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting server on port 8003...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/02 15:27:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/05/02 15:27:36 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/05/02 15:27:36 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "127.0.0.1 - - [02/May/2024 15:27:39] \"GET /highest_covid_cases_country HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [02/May/2024 15:27:39] \"GET /favicon.ico HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "from http.server import BaseHTTPRequestHandler, HTTPServer\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "import os\n",
    "from glob import glob\n",
    "import json\n",
    "\n",
    "class HTTPRequestHandler(BaseHTTPRequestHandler):\n",
    "    def do_GET(self):\n",
    "        if self.path == '/highest_covid_cases_country':\n",
    "            # Create a SparkSession\n",
    "            spark = SparkSession.builder \\\n",
    "                .appName(\"Highest COVID Cases Country\") \\\n",
    "                .getOrCreate()\n",
    "\n",
    "            # Define the directory containing the CSV files\n",
    "            directory = \"/Users/saumya/Documents/spark-project/\"\n",
    "\n",
    "            # Find all CSV files in the directory\n",
    "            file_paths = glob(os.path.join(directory, \"*.csv\"))\n",
    "\n",
    "            # Read each CSV file into a DataFrame\n",
    "            dfs = [spark.read.csv(file_path, header=True, inferSchema=True) for file_path in file_paths]\n",
    "\n",
    "            # Union all DataFrames\n",
    "            merged_df = dfs[0]\n",
    "            for df in dfs[1:]:\n",
    "                merged_df = merged_df.union(df)\n",
    "\n",
    "            # Find the country with the highest number of COVID cases\n",
    "            highest_cases_country = merged_df.orderBy(col(\"cases\").desc()).select(\"country\").first()[0]\n",
    "\n",
    "            # Stop the SparkSession\n",
    "            spark.stop()\n",
    "\n",
    "            # Send response\n",
    "            self.send_response(200)\n",
    "            self.send_header('Content-type', 'application/json')\n",
    "            self.end_headers()\n",
    "            response = {'highest_covid_cases_country': highest_cases_country}\n",
    "            self.wfile.write(json.dumps(response).encode())\n",
    "\n",
    "        else:\n",
    "            # Send 404 response for other paths\n",
    "            self.send_response(404)\n",
    "            self.end_headers()\n",
    "            self.wfile.write(b'404 Not Found')\n",
    "\n",
    "def run_server(port=8003):\n",
    "    server_address = ('', port)\n",
    "    httpd = HTTPServer(server_address, HTTPRequestHandler)\n",
    "    print(f'Starting server on port {port}...')\n",
    "    httpd.serve_forever()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_server()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
